{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionalNeuralNetwork.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhAP+NX9rSA7XuOg3eNDUS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thmnmht/ConvNet/blob/main/ConvolutionalNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AWLpt1fBkRd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest' \n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    X_pad = np.pad(X, ((0,0), (pad, pad), (pad, pad), (0,0)), mode='constant', constant_values = (0,0))\n",
        "    \n",
        "    \n",
        "    return X_pad"
      ],
      "metadata": {
        "id": "P6fquPDpkeE8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 3)\n",
        "print (\"x.shape =\\n\", x.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[1,1] =\\n\", x[1, 1])\n",
        "print (\"x_pad[1,1] =\\n\", x_pad[1, 1])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0, :, :, 0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0, :, :, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "RFhacqUqlBRY",
        "outputId": "942425fe-bf7c-437c-eb3b-a5b9158b8d70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape =\n",
            " (4, 3, 3, 2)\n",
            "x_pad.shape =\n",
            " (4, 9, 9, 2)\n",
            "x[1,1] =\n",
            " [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] =\n",
            " [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fad6f422510>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    \"\"\"\n",
        "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
        "    of the previous layer.\n",
        "    \n",
        "    Arguments:\n",
        "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
        "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
        "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "    \n",
        "    Returns:\n",
        "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "    \"\"\"\n",
        "    \n",
        "    # Element-wise product between a_slice_prev and W.\n",
        "    s = a_slice_prev * W\n",
        "    # Sum over all entries of the volume s.\n",
        "    Z = np.sum(s)\n",
        "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
        "    Z = Z + float(b)\n",
        "    \n",
        "    return Z"
      ],
      "metadata": {
        "id": "-OdSgzq_lau8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "Z = conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXqIgXVml-bS",
        "outputId": "97f5dd05-e8f5-465b-a623-8e32fb7c77ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z = -6.999089450680221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- output activations of the previous layer, \n",
        "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
        "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
        "        \n",
        "    Returns:\n",
        "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward() function\n",
        "    \"\"\"\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    # Compute the dimensions of the CONV output volume\n",
        "    n_H = int((n_H_prev - f + 2 * pad)/stride) + 1\n",
        "    n_W = int((n_W_prev - f + 2 * pad)/stride) + 1\n",
        "    \n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):\n",
        "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
        "        for h in range(n_H):\n",
        "            vert_start = h * stride\n",
        "            vert_end = vert_start + f\n",
        "            \n",
        "            for w in range(n_W):\n",
        "                horiz_start = w * stride\n",
        "                horiz_end = horiz_start + f\n",
        "                \n",
        "                for c in range(n_C):\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    \n",
        "                    weights = W[:, :, :, c]\n",
        "                    biases = b[:, :, :, c]\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
        "    \n",
        "    # Save information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "metadata": {
        "id": "gP07HiiBmDjx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 7, 4)\n",
        "W = np.random.randn(3, 3, 4, 8)\n",
        "b = np.random.randn(1, 1, 1, 8)\n",
        "hparameters = {\"pad\" : 1,\n",
        "               \"stride\": 2}\n",
        "\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "z_mean = np.mean(Z)\n",
        "z_0_2_1 = Z[0, 2, 1]\n",
        "cache_0_1_2_3 = cache_conv[0][1][2][3]\n",
        "print(\"Z's mean =\\n\", z_mean)\n",
        "print(\"Z[0,2,1] =\\n\", z_0_2_1)\n",
        "print(\"cache_conv[0][1][2][3] =\\n\", cache_0_1_2_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcIMU_8hnajp",
        "outputId": "bc06a890-d5b3-45c1-ee9b-2554ece04f73"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z's mean =\n",
            " 0.5511276474566768\n",
            "Z[0,2,1] =\n",
            " [-2.17796037  8.07171329 -0.5772704   3.36286738  4.48113645 -2.89198428\n",
            " 10.99288867  3.03171932]\n",
            "cache_conv[0][1][2][3] =\n",
            " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    \"\"\"\n",
        "    Implements the forward pass of the pooling layer\n",
        "    \n",
        "    Arguments:\n",
        "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
        "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
        "    \"\"\"\n",
        "    \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    # Retrieve hyperparameters from \"hparameters\"\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "    \n",
        "    # Define the dimensions of the output\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    for i in range(m):\n",
        "        for h in range(n_H):\n",
        "            vert_start = h * stride\n",
        "            vert_end = vert_start + f\n",
        "            \n",
        "            for w in range(n_W):\n",
        "                horiz_start = w * stride\n",
        "                horiz_end = horiz_start + f\n",
        "                \n",
        "                for c in range(n_C):\n",
        "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                    \n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    return A, cache"
      ],
      "metadata": {
        "id": "Sk9i-MNtngCe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 1, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"max\")\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[1, 1] =\\n\", A[1, 1])\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[1, 1] =\\n\", A[1, 1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dNLzwe4od6e",
        "outputId": "d48728fe-6981-49e5-c321-c52f099eba85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode = max\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A[1, 1] =\n",
            " [[1.96710175 0.84616065 1.27375593]\n",
            " [1.96710175 0.84616065 1.23616403]\n",
            " [1.62765075 1.12141771 1.2245077 ]]\n",
            "mode = average\n",
            "A.shape = (2, 3, 3, 3)\n",
            "A[1, 1] =\n",
            " [[ 0.44497696 -0.00261695 -0.31040307]\n",
            " [ 0.50811474 -0.23493734 -0.23961183]\n",
            " [ 0.11872677  0.17255229 -0.22112197]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "hparameters = {\"stride\" : 2, \"f\": 3}\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters)\n",
        "print(\"mode = max\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[0] =\\n\", A[0])\n",
        "print()\n",
        "\n",
        "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
        "print(\"mode = average\")\n",
        "print(\"A.shape = \" + str(A.shape))\n",
        "print(\"A[1] =\\n\", A[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-aorw50ojr0",
        "outputId": "246a24c4-362e-433f-b818-fc7b180c4cb2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode = max\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A[0] =\n",
            " [[[1.74481176 0.90159072 1.65980218]\n",
            "  [1.74481176 1.6924546  1.65980218]]\n",
            "\n",
            " [[1.13162939 1.51981682 2.18557541]\n",
            "  [1.13162939 1.6924546  2.18557541]]]\n",
            "\n",
            "mode = average\n",
            "A.shape = (2, 2, 2, 3)\n",
            "A[1] =\n",
            " [[[-0.17313416  0.32377198 -0.34317572]\n",
            "  [ 0.02030094  0.14141479 -0.01231585]]\n",
            "\n",
            " [[ 0.42944926  0.08446996 -0.27290905]\n",
            "  [ 0.15077452  0.28911175  0.00123239]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a convolution function\n",
        "    \n",
        "    Arguments:\n",
        "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
        "    cache -- cache of values needed for the conv_backward(), output of conv_forward()\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
        "               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    dW -- gradient of the cost with respect to the weights of the conv layer (W)\n",
        "          numpy array of shape (f, f, n_C_prev, n_C)\n",
        "    db -- gradient of the cost with respect to the biases of the conv layer (b)\n",
        "          numpy array of shape (1, 1, 1, n_C)\n",
        "    \"\"\"    \n",
        "    \n",
        "    (A_prev, W, b, hparameters) = cache\n",
        "    \n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    \n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "    \n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "    dW = np.zeros(W.shape)\n",
        "    db = np.zeros(b.shape)\n",
        "    \n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):\n",
        "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
        "        da_prev_pad = dA_prev_pad[i, :, :, :]\n",
        "        \n",
        "        for h in range(n_H):\n",
        "            for w in range(n_W):\n",
        "                for c in range(n_C):\n",
        "                    vert_start = h * stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w * stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    # Update gradients for the window and the filter's parameters\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "        # Set the ith training example's dA_prev to the unpadded da_prev_pad\n",
        "        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
        "    # Making sure output shape is correct\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "ez6Du89von5a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll run conv_forward to initialize the 'Z' and 'cache_conv\",\n",
        "# which we'll use to test the conv_backward function\n",
        "np.random.seed(1)\n",
        "A_prev = np.random.randn(10, 4, 4, 3)\n",
        "W = np.random.randn(2, 2, 3, 8)\n",
        "b = np.random.randn(1, 1, 1, 8)\n",
        "hparameters = {\"pad\" : 2,\n",
        "               \"stride\": 2}\n",
        "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
        "\n",
        "# Test conv_backward\n",
        "dA, dW, db = conv_backward(Z, cache_conv)\n",
        "\n",
        "print(\"dA_mean =\", np.mean(dA))\n",
        "print(\"dW_mean =\", np.mean(dW))\n",
        "print(\"db_mean =\", np.mean(db))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyNUD_WNqMxe",
        "outputId": "1f739c7a-f5cb-43af-9d5d-3747066feaee"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dA_mean = 1.4524377775388075\n",
            "dW_mean = 1.7269914583139097\n",
            "db_mean = 7.839232564616838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask_from_window(x):\n",
        "    \"\"\"\n",
        "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- Array of shape (f, f)\n",
        "    \n",
        "    Returns:\n",
        "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
        "    \"\"\"    \n",
        "    mask = (x == np.max(x))\n",
        "    return mask"
      ],
      "metadata": {
        "id": "a0RHv-_4qYF1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(2, 3)\n",
        "mask = create_mask_from_window(x)\n",
        "print('x = ', x)\n",
        "print(\"mask = \", mask)\n",
        "\n",
        "x = np.array([[-1, 2, 3],\n",
        "              [2, -3, 2],\n",
        "              [1, 5, -2]])\n",
        "\n",
        "y = np.array([[False, False, False],\n",
        "     [False, False, False],\n",
        "     [False, True, False]])\n",
        "mask = create_mask_from_window(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7I---OGqmSD",
        "outputId": "88c543c1-6f0f-460b-81af-6b1ffd21e123"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
            " [-1.07296862  0.86540763 -2.3015387 ]]\n",
            "mask =  [[ True False False]\n",
            " [False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def distribute_value(dz, shape):\n",
        "    \"\"\"\n",
        "    Distributes the input value in the matrix of dimension shape\n",
        "    \n",
        "    Arguments:\n",
        "    dz -- input scalar\n",
        "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
        "    \n",
        "    Returns:\n",
        "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
        "    \"\"\"    \n",
        "    (n_H, n_W) = shape\n",
        "    # Compute the value to distribute on the matrix\n",
        "    average = dz / (n_H * n_W)\n",
        "    # Create a matrix where every entry is the \"average\" value\n",
        "    a = np.ones(shape) * average\n",
        "    \n",
        "    return a"
      ],
      "metadata": {
        "id": "YmbEZ8iaqqi6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = distribute_value(2, (2, 2))\n",
        "print('distributed value =', a)\n",
        "\n",
        "a = distribute_value(100, (10, 10))\n",
        "print('distributed value =', a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBD--g-ZrQLZ",
        "outputId": "47ee9f19-19dd-4a27-f8f9-f03f7c17b21f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distributed value = [[0.5 0.5]\n",
            " [0.5 0.5]]\n",
            "distributed value = [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qjV1YADXrUo0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}